---
layout: post
title:  "2017 BigContest) 2. 모델링 과정 및 결과"
date:   2018-08-02 12:00:00
author: Yeongrong Bak
categories: DataCompetition
tags: Competition Bigcon Bigdata
---

데이터 전처리와 파생변수 생성을 마친 뒤 적용해야될 알고리즘을 비교해가면서 데이터 특성에 맞는 모델링을 적용하고자 노력했습니다.

## 1) 모델링 과정

(1) 차원 축소 : **PCA(주성분 분석)**

- 변수 간의 상관관계가 높아서 작은 Dimension 으로 축소하는 방법을 고려했으나, 적은 주성분으로는 전체 변동을 충분히 설명할 수 없었음

(2) 샘플링 방법 : **Under Sampling, Over Sampling, SMOTE**

- 불균형 데이터임을 고려하여 Sampling 방법을 적용하고자 했으나 다음과 같은 문제가 발생했다
	-  Under Sampling 은 정보의 손실
	-  Over Sampling은 과적합의 문제 발생
	-  SMOTE는 KNN 알고리즘을 기반으로 하여 차원이 높아졌을 때 설명력		 이 떨어진다.

(3) **로지스틱 회귀, SVM, 의사결정나무, 랜덤포레스트 ,GBM, XGB 의 분류 기법 비교 적용**

- 분류 기법에 사용되는 다양한 알고리즘을 적용해 보았고, 로지스틱 회귀를 기본 모형으로 F-measure 값을 비교해가면서 적용해보았다. 

- 결과적으로 트리 앙상블 모형인 GBM과 XGB가 가장 높은 성능을 가지는 것을 알 수 있었고 이를 최종 모형으로 선정하고 파라미터를 세부적으로 튜닝 하는 과정을 진행했다.

(4) GBM과 XGB의 하이퍼 파라미터는 다른 모형에 비해 매우 다양하다.

- 이에 따라 파라미터의 최적 조합을 찾는데에 시간 소요가 많이 되었다.

- Grid Search로 기준값을 찾고 Heuristic한 방법으로 세부 튜닝을 진행했다. 

- 대부분의 참가 팀이 이러한 방법으로 파라미터 튜닝을 했었지만, 가장 우수한 평가를 받은 팀(1등 팀)의 경우에는 Parameter search 과정에서 Bayesian 을 적용한 점이 차별화 포인트였다고 생각한다.

## 2) 결론 도출

(1) 최종 적용한 부스팅 모형이 왜 최종 모형으로 가장 적합한가?에 대한 적절한 이유 설명이 중요했다.

- 불균형 데이터를 분류하는 데 가장 높은 성능을 보였음 : 이전 분류기의 오분류에 집중하여 연속적으로 보완해가는 형태의 알고리즘 이었기 때문

- 다른 트리 앙상블 모형(ex. 랜덤포레스트)에 비해 높은 정확도 : Bias 최소화에 더 집중하는 알고리즘

- 높은 정확도 + 변수 중요도 설명 가능 : 신용 평가에 관련된 모형이므로 해석력이 필요할 것이라고 생각(더 복잡한 모형을 선택하지 않은 이유)

(2) 분류 성능을 더 끌어올릴 수 있는 방법은 없을까? Stacking 방법을 적용해 보았으나 성능이 크게 상승하지는 않았음. 
- 효율성, 설명가능성을 종합적으로 고려했을 때, XGB 단일 모형보다 나은 방법이라고 볼 수 없었음.

## 3) 마치며...

- 분류 모델에 대한 다양한 알고리즘을 비교할 수 있었고 그 중에서도 부스팅 모형에 대한 구체적인 이해와 실제 적용을 해볼 수 있는 대회였다

- 시간이 많이 소요되는 Parameter Search 과정에서 효율성을 높이는 방법이 굉장히 중요했고, Microsoft Azure 를 이용한 점은 효율성 제고에 도움이 되었다

- 하지만 베이지안 방법을 사용한 Parameter search를 한 팀(1위를 수상한 팀)보다 효율적이지 않은 방법이었고, 향후 이러한 부분에 대한 추가적인 학습이 필요하다.(그렇지만 베이지안은 어렵다...)

- 타 팀의 발표를 보면서, 같은 주제이지만 풀어나가는 방향이나 데이터를 바라보는 시각이 매우 다를 수 있다는 것을 알 수 있었다.

- 본선에 진출한 모든 팀의 최종 모형이 XGB알고리즘 이었다는 것은 모델링에 있어서 차별점은 '알고리즘'이 아닌 '데이터 전처리 및 파생변수 생성'이 된다고 볼 수 있었다.

- 알고리즘은 간단한 이해와 활용만 할 줄 알면 되고(비록 효율성 문제가 연결이 되긴 하지만) 알고리즘에 적용되는 INPUT 변수에 대한 Feature Engineering에 더 신경써야 한다고 판단할 수 있다.
