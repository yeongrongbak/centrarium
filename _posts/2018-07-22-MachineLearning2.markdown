---
layout: post
title:  "머신러닝(Machine Learning)이란?"
date:   2018-07-22 10:00:00
author: Yeongrong Bak
categories: MachineLearning
tags: ML MachineLearning Datamining
---

머신러닝에 관한 **첫 포스팅**입니다.

핸즈온 머신러닝의 1장에 대해 공부하고 요약한 내용을 바탕으로 머신러닝의 개괄적인 내용에 대해서 정리하겠습니다.

## **1. 머신러닝이란?**

- 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술)

- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야

- 데이터 마이닝 : 대용량의 데이터를 분석하면서 겉으로 보이지 않는 패턴을 발견하는 머신러닝 기술

## **2. 머신러닝은 어느 분야에서 뛰어난가?**

- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제

- 전통적인 방식으로는 전혀 해결 방법이 없는 문제

## **3. 머신러닝의 종류**

- 지도, 준지도, 비지도, 강화 학습 (사람의 감독 하에 훈련하는지 여부)

- 온라인학습, 배치학습 (실시간으로 점진적인 학습을 하는지 여부)

- 사례기반학습, 모델기반학습 (단순히 기존데이터와 새 데이터를 비교하는지 패턴을 발견해서 예측 모델을 만드는지 여부)


## **4. 주요 개념 정리**

- **지도학습(Supervised Learning)** : 알고리즘에 주입하는 훈련데이터에 레이블 이라는 원하는 답이 포함되어 있는 문제를 학습해서 새로운 데이터 분류/예측

> -분류(Classification) : 종속 변수의 Class가 범주형(Categorical) 변수 인 경우 

> -예측(Prediction) : 종속 변수의 Class가 연속형(Continuous) 변수 인 경우 

> -대표 알고리즘 : KNN, Linear Regression, Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, Neural Net

- **비지도학습(Unsupervised Learning)** : 훈련 데이터에 레이블이 없는 문제를 시스템이 아무런 도움 없이 스스로 학습한 뒤 데이터 안에서 패턴을 발견

> -대표 알고리즘 : K-means, Hierarchical Clustering, Expectation Maximization, PCA, Locally Linear Embedding, t-SNE, Apriori, Eclat

- **준지도학습(Semisuperviese Learning)** : 레이블이 없는 데이터는 많고 레이블이 있는 데이터는 조금인 케이스

> -대표 알고리즘 : Deep belief network

- **강화학습(Reinforcement Learning)** : 환경을 관찰해서 행동을 실행하고 그 결과로 보상(또는 벌점)을 받는 과정을 거친다. 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습하는 과정

> -사용 분야 : 보행 로봇에 사용되는 알고리즘, 알파고 프로그램

- **배치학습(Batch Learning)** :  시스템이 점진적으로 학습할 수 없는 케이스, 오프라인으로 시스템을 훈련시키고 제품 시스템에 적용시에는 학습한 것을 적용만 함

> -장점 : 간단하고 잘 작동한다

> -단점 : 매일 새롭게 훈련해야 하는 문제가 있다

- **온라인학습(Online Learning)** : 데이터를 순차적으로 한 개씩 또는 미니배치(mini-batch)라 부르는 작은 묶은 단위로 주입하여 시스템을 훈련

> -장점 : 매 학습 단계가 빠르고 비용이 적어 시스템은 데이터 도착 즉시 학습 가능

> -**학습률(Learning rate)** : 변화하는 데이터에 대해 얼마나 빠르게 적응할 것인가를 결정해주는 파라미터

- **사례기반학습(Instance Based Learning)** : 시스템이 사례를 기억함으로써 학습하고 유사도 측정을 사용해 새로운 데이터에 일반화

- **모델기반학습(Model Based Learing)** : 샘플들의 모델을 만들어서 예측에 사용하는 방법

- **과대적합(Overfitting)** : 훈련 데이터에는 너무 잘 맞지만 일반성이 떨어지는 케이스(훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할때 발생)

> -해결 방법 : 1) 파라미터 수가 적은 모델 선택 2) 모델에 제약을 가한다 3) 훈련 데이터를 더 모은다 4) 훈련 데이터의 잡음을 줄인다

> -**규제(Regularization)** : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것

- **과소적합(Underfitting)** : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생

> -해결 방법 : 1) 파라미터 수가 더 많은 모델 선택 2)학습 알고리즘에 더 좋은 변수 제공 3) 모델의 제약을 줄인다

- **테스트와 검증(Test and Validation)**

> -**일반화 오차(Generalization Error)** : 새로운 샘플에 대한 오류 비율

> 훈련 오차가 낮지만 일반화 오차가 크다면 해당 모형은 과대적합된 케이스

> 1) 훈련 세트에서 다양한 하이퍼 파라미터로 여러 모델을 훈련

> 2) 검증 세트에서 최상의 성능을 내는 모델과 하이퍼 파라미터를 선택

> 3) 만족스러운 모델을 찾은 뒤 일반화 오차의 추정값을 얻기 위해 테스트 셋으로 **단 한번의** 최종 테스트

- **교차검증(Cross Validation)**

> 1) 훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뺏기지 않기 위해서 사용

> 2) 훈련 세트를 여러 서브셋으로 나누고 각 모델을 이 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증

> 3) 모델과 하이퍼파라미터가 선택되면 전체 훈련 데이터를 사용해 선택한 하이퍼 파라미터로 최종 모델을 훈련 시키고 테스트 세트로 일반화 오차를 추정
